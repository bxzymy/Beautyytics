import json

import duckdb
import pandas as pd
import streamlit as st

from chart import generate_streamlit_chart
from llm_response import get_llm_response_structured, get_final_analysis_and_chart_details, get_synthesized_report, get_analysis_plan
from prompt.prompt import FULL_SYSTEM_PROMPT, DATA_ANALYSIS_PROMPT_TEMPLATE, DATA_CAVEATS_INSTRUCTIONS
from prompt.prompt_en import FULL_SYSTEM_PROMPT_EN, DATA_ANALYSIS_PROMPT_TEMPLATE_EN, DATA_CAVEATS_INSTRUCTIONS_EN

# Language strings
LANGUAGE_STRINGS = {
    'zh': {
        'sql_empty': "SQL æŸ¥è¯¢ä¸ºç©ºæˆ–æ— æ•ˆã€‚",
        'data_not_loaded': "æ•°æ®æœªèƒ½åŠ è½½ï¼Œæ— æ³•æ‰§è¡ŒSQLæŸ¥è¯¢ã€‚",
        'sql_error': "SQL æŸ¥è¯¢æ‰§è¡Œé”™è¯¯: {error}\nå°è¯•æ‰§è¡Œçš„ SQL: {query}",
        'ai_thinking': "AI æ€è€ƒä¸­...",
        'ai_thinking_framework': "AI æ ¹æ® ({framework}) æ¡†æ¶æ€è€ƒä¸­...",
        'ai_failed': "æŠ±æ­‰ï¼ŒAIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„SQLæŸ¥è¯¢æˆ–åˆ†æå»ºè®®ã€‚è¯·ç¨åå†è¯•æˆ–è°ƒæ•´æ‚¨çš„é—®é¢˜ã€‚",
        'ai_guidance': "AI æŒ‡å¯¼: {text}",
        'data_insights': "##### ğŸ¤– AI æ•°æ®æ´å¯Ÿ",
        'analyzing_data': "AI æ­£åœ¨åˆ†ææ•°æ®...",
        'analyzing_data_framework': "AI æ­£åŸºäº ({framework}) æ¡†æ¶åˆ†ææ•°æ®...",
        'results_chart': "ğŸ“‹ **æŸ¥è¯¢ç»“æœä¸å›¾è¡¨:**",
        'no_analysis_text': "æœ¬æ¬¡æœªèƒ½ä»AIè·å–æ•°æ®åˆ†ææ–‡æœ¬ã€‚",
        'analysis_failed': "AIæœªèƒ½å®Œæˆæ•°æ®åˆ†æã€‚å°†å°è¯•ä½¿ç”¨åˆæ­¥çš„å›¾è¡¨å»ºè®®ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚",
        'preliminary_chart': "ğŸ“‹ **æŸ¥è¯¢ç»“æœä¸å›¾è¡¨ (åŸºäºåˆæ­¥å»ºè®®):**",
        'no_data': "æŸ¥è¯¢å·²æˆåŠŸæ‰§è¡Œï¼Œä½†æ²¡æœ‰è¿”å›ä»»ä½•æ•°æ®ã€‚",
        'no_results': "æŸ¥è¯¢æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œä¹Ÿæ— æ˜ç¡®é”™è¯¯ä¿¡æ¯ã€‚",
        'no_sql': "AI æœªèƒ½ç”Ÿæˆ SQL æŸ¥è¯¢æˆ–æä¾›æ˜ç¡®æŒ‡å¯¼ã€‚",
        'suggestions': "ğŸ’¡ æˆ–è®¸æ‚¨å¯¹ä»¥ä¸‹åˆ†ææ–¹å‘æ„Ÿå…´è¶£ï¼Ÿ",
        'no_action': "AI è¿”å›äº†å“åº”ï¼Œä½†æ²¡æœ‰å…·ä½“çš„æ“ä½œæˆ–å»ºè®®ã€‚"
    },
    'en': {
        'sql_empty': "SQL query is empty or invalid.",
        'data_not_loaded': "Data failed to load, cannot execute SQL query.",
        'sql_error': "SQL query execution error: {error}\nAttempted SQL: {query}",
        'ai_thinking': "AI is thinking...",
        'ai_thinking_framework': "AI is thinking using ({framework}) framework...",
        'ai_failed': "Sorry, the AI failed to generate a valid SQL query or analysis suggestion. Please try again later or adjust your question.",
        'ai_guidance': "AI Guidance: {text}",
        'data_insights': "##### ğŸ¤– AI Data Insights",
        'analyzing_data': "AI is analyzing data...",
        'analyzing_data_framework': "AI is analyzing data using ({framework}) framework...",
        'results_chart': "ğŸ“‹ **Query Results & Chart:**",
        'no_analysis_text': "Could not get data analysis text from AI this time.",
        'analysis_failed': "AI failed to complete data analysis. Will try to use preliminary chart suggestion (if available).",
        'preliminary_chart': "ğŸ“‹ **Query Results & Chart (Preliminary):**",
        'no_data': "Query executed successfully but returned no data.",
        'no_results': "Query returned no valid results and no clear error message.",
        'no_sql': "AI failed to generate SQL query or provide clear guidance.",
        'suggestions': "ğŸ’¡ You might be interested in these analysis directions?",
        'no_action': "AI returned a response but no specific actions or suggestions."
    }
}


def get_text(key, lang='zh', **kwargs):
    """Helper function to get localized text with optional formatting"""
    return LANGUAGE_STRINGS[lang][key].format(**kwargs)


def execute_sql(sql_query: str, current_df_data: pd.DataFrame):
    if not sql_query or not sql_query.strip():
        return None, get_text('sql_empty')
    if current_df_data is None:
        return None, get_text('data_not_loaded')
    try:
        con = duckdb.connect(database=':memory:', read_only=False)
        con.register('df_data', current_df_data)
        result_df = con.execute(sql_query).fetchdf()
        con.close()
        return result_df, None
    except Exception as e:
        error_message = get_text('sql_error', error=e, query=sql_query)
        return None, error_message


def process_user_query(user_query: str, current_df_data: pd.DataFrame, active_analysis_framework_prompt: str = None,
                       lang='zh'):
    system_prompt = FULL_SYSTEM_PROMPT_EN if lang == 'en' else FULL_SYSTEM_PROMPT
    analysis_prompt_template = DATA_ANALYSIS_PROMPT_TEMPLATE_EN if lang == 'en' else DATA_ANALYSIS_PROMPT_TEMPLATE
    data_caveats = DATA_CAVEATS_INSTRUCTIONS_EN if lang == 'en' else DATA_CAVEATS_INSTRUCTIONS

    st.session_state.llm_conversation_history.append({"role": "user", "content": user_query})

    default_framework_name = "é€šç”¨åˆ†æ (é»˜è®¤)" if lang == 'zh' else "General Analysis (Default)"
    selected_prompt_display_name = st.session_state.get("selected_analysis_prompt_display_name", default_framework_name)

    ui_user_content = user_query
    if active_analysis_framework_prompt and selected_prompt_display_name != default_framework_name:
        framework_prefix = "(Using framework: " if lang == 'en' else "ï¼ˆä½¿ç”¨åˆ†ææ¡†æ¶ï¼š"
        framework_suffix = ")" if lang == 'en' else "ï¼‰"
        ui_user_content = f"{framework_prefix}{selected_prompt_display_name}{framework_suffix}\n{user_query}"

    st.session_state.ui_messages.append({"role": "user", "content": ui_user_content})

    with st.chat_message("user"):
        st.markdown(ui_user_content)

    with st.chat_message("assistant"):
        assistant_ui_msg = {
            "role": "assistant",
            "analysis_framework_used": selected_prompt_display_name if active_analysis_framework_prompt else None,
            "sql_query": None,
            "chart_type": "table",
            "chart_params": {},
            "recommended_analyses": None,
            "llm_general_explanation": None,
            "query_result_df": None,
            "error_message": None,
            "data_analysis_text": None,
            "final_chart_explanation": None
        }

        # Determine spinner text based on language and framework
        spinner_text = get_text('ai_thinking', lang)
        if active_analysis_framework_prompt:
            spinner_text = get_text('ai_thinking_framework', lang, framework=selected_prompt_display_name)

        with st.spinner(spinner_text):
            llm_response_call1_data = get_llm_response_structured(
                st.session_state.llm_conversation_history,
                system_prompt,
                active_analysis_framework_prompt=active_analysis_framework_prompt,
                lang=lang
            )

        if not llm_response_call1_data:
            error_msg = get_text('ai_failed', lang)
            st.error(error_msg)
            assistant_ui_msg["error_message"] = error_msg
            st.session_state.llm_conversation_history.append({"role": "assistant", "content": f"Error: {error_msg}"})
            st.session_state.ui_messages.append(assistant_ui_msg)
            return

        generated_sql = llm_response_call1_data.get("sql_query")
        preliminary_chart_type = llm_response_call1_data.get("chart_type", "table")
        preliminary_chart_params = llm_response_call1_data
        assistant_ui_msg.update({
            "llm_general_explanation": llm_response_call1_data.get("explanation"),
            "recommended_analyses": llm_response_call1_data.get("recommended_analyses"),
            "sql_query": generated_sql,
            "chart_type": preliminary_chart_type,
            "chart_params": preliminary_chart_params
        })

        try:
            llm1_context_content = json.dumps(llm_response_call1_data)
        except TypeError:
            llm1_context_content = str(llm_response_call1_data)
        st.session_state.llm_conversation_history.append({"role": "assistant", "content": llm1_context_content})

        if assistant_ui_msg["llm_general_explanation"]:
            st.info(get_text('ai_guidance', lang, text=assistant_ui_msg["llm_general_explanation"]))

        query_result_df = None
        error_msg_sql = None

        if generated_sql and generated_sql.strip():
            print(f"Generated SQL (from LLM Call 1 - hidden from UI): {generated_sql}")
            query_result_df, error_msg_sql = execute_sql(generated_sql, current_df_data)
            assistant_ui_msg["query_result_df"] = query_result_df
            assistant_ui_msg["error_message"] = error_msg_sql

            if error_msg_sql:
                st.error(error_msg_sql)
            elif query_result_df is not None:
                if not query_result_df.empty:
                    st.markdown("---")
                    st.markdown(get_text('data_insights', lang))

                    analysis_spinner_text = get_text('analyzing_data', lang)
                    if active_analysis_framework_prompt:
                        analysis_spinner_text = get_text('analyzing_data_framework', lang,
                                                         framework=selected_prompt_display_name)

                    with st.spinner(analysis_spinner_text):
                        llm_response_call2_data = get_final_analysis_and_chart_details(
                            data_df=query_result_df,
                            user_query_for_analysis=user_query,
                            active_analysis_framework_prompt=active_analysis_framework_prompt,
                            base_data_analysis_prompt_template=analysis_prompt_template,
                            data_caveats_instructions=data_caveats,
                            lang=lang
                        )

                    if llm_response_call2_data:
                        assistant_ui_msg["data_analysis_text"] = llm_response_call2_data.get("analysis_text")
                        assistant_ui_msg["chart_type"] = llm_response_call2_data.get("chart_type",
                                                                                     preliminary_chart_type)
                        final_chart_params = {
                            "x_axis": llm_response_call2_data.get("x_axis"),
                            "y_axis": llm_response_call2_data.get("y_axis"),
                            "category_column": llm_response_call2_data.get("category_column"),
                            "value_column": llm_response_call2_data.get("value_column"),
                            "title": llm_response_call2_data.get("title", preliminary_chart_params.get("title",
                                                                                                       "åˆ†æç»“æœå›¾è¡¨" if lang == 'zh' else "Analysis Results Chart")),
                            "explanation": llm_response_call2_data.get("explanation")
                        }
                        assistant_ui_msg["chart_params"] = final_chart_params
                        assistant_ui_msg["final_chart_explanation"] = final_chart_params.get("explanation")

                        st.markdown(get_text('results_chart', lang))
                        current_chart_title = assistant_ui_msg["chart_params"].get("title")
                        generate_streamlit_chart(
                            assistant_ui_msg["chart_type"],
                            query_result_df,
                            assistant_ui_msg["chart_params"],
                            chart_key=f"current_chart_{len(st.session_state.ui_messages)}_{current_chart_title.replace(' ', '_')}"
                        )

                        if assistant_ui_msg["data_analysis_text"]:
                            st.info(assistant_ui_msg["data_analysis_text"])
                        else:
                            st.warning(get_text('no_analysis_text', lang))
                    else:
                        st.warning(get_text('analysis_failed', lang))
                        if not query_result_df.empty and preliminary_chart_type:
                            current_chart_title = preliminary_chart_params.get("title",
                                                                               "åˆæ­¥åˆ†æå›¾è¡¨" if lang == 'zh' else "Preliminary Analysis Chart")
                            st.markdown(get_text('preliminary_chart', lang))
                            generate_streamlit_chart(
                                preliminary_chart_type,
                                query_result_df,
                                preliminary_chart_params,
                                chart_key=f"prelim_chart_{len(st.session_state.ui_messages)}_{current_chart_title.replace(' ', '_')}"
                            )
                else:
                    st.info(get_text('no_data', lang))
            else:
                st.warning(get_text('no_results', lang))

        elif assistant_ui_msg["recommended_analyses"]:
            pass
        elif not assistant_ui_msg["llm_general_explanation"]:
            st.markdown(get_text('no_sql', lang))

        if assistant_ui_msg["recommended_analyses"]:
            st.markdown(get_text('suggestions', lang))
            for i, rec in enumerate(assistant_ui_msg["recommended_analyses"]):
                title_rec, desc_rec, ex_query = rec.get('title'), rec.get('description'), rec.get('example_query')
                with st.container():
                    st.markdown(f"##### {title_rec}")
                    st.markdown(desc_rec)
                    if ex_query:
                        key = f"rec_btn_{i}_{user_query[:10].replace(' ', '_')}_{len(st.session_state.ui_messages)}"
                        btn_text = f"Try query: \"{ex_query}\"" if lang == 'en' else f"å°è¯•æŸ¥è¯¢: \"{ex_query}\""
                        if st.button(btn_text, key=key):
                            st.session_state.selected_suggestion_query = ex_query
                            st.rerun()
                    st.markdown("---")

        if not generated_sql and not assistant_ui_msg["recommended_analyses"] and \
                not assistant_ui_msg["llm_general_explanation"] and not assistant_ui_msg["data_analysis_text"]:
            st.info(get_text('no_action', lang))

        st.session_state.ui_messages.append(assistant_ui_msg)


def process_user_query_orchestrator(user_query, df_data, lang='en'):
    """
    ã€çŠ¶æ€æœºæ¨¡å¼ã€‘å¤„ç†æ™ºèƒ½æŠ¥å‘Šè¯·æ±‚ã€‚
    æ­¤å‡½æ•°ç°åœ¨ä½œä¸ºçŠ¶æ€è·¯ç”±å™¨ï¼Œæ ¹æ®å½“å‰ job_status æ‰§è¡Œç›¸åº”é˜¶æ®µã€‚
    """
    # å¦‚æœä»»åŠ¡ä¸å­˜åœ¨ï¼Œåˆ™åˆå§‹åŒ–
    if "current_analysis_job" not in st.session_state:
        print("\n================== [æ™ºèƒ½æŠ¥å‘Šæµç¨‹åˆå§‹åŒ–] ==================")
        print(f"ç”¨æˆ·é—®é¢˜: {user_query}")
        initial_status_message = "æ™ºèƒ½æŠ¥å‘Šä»»åŠ¡å·²å¯åŠ¨..." if lang == 'zh' else "Smart Report task initiated..."
        st.session_state.current_analysis_job = {
            "job_status": "STARTED",  # åˆå§‹çŠ¶æ€
            "original_query": user_query,
            "stages": {},
            "status_message": initial_status_message,
            "stage_info": "é˜¶æ®µ 1/4ï¼šå‡†å¤‡ä¸­..." if lang == 'zh' else "Stage 1/4: Preparing..."
        }
        st.rerun()
        return

    # è·å–å½“å‰ä»»åŠ¡å’ŒçŠ¶æ€
    job = st.session_state.current_analysis_job
    status = job.get("job_status")

    # --- çŠ¶æ€è·¯ç”± ---

    # é˜¶æ®µä¸€ï¼šä» "STARTED" çŠ¶æ€å¼€å§‹ï¼Œç”Ÿæˆåˆæ­¥SQL
    if status == "STARTED":
        print("\n[Orchestrator] ==> STAGE 1: ç”Ÿæˆåˆæ­¥SQLæŸ¥è¯¢...")
        job.update({
            "status_message": "æ­£åœ¨ç”Ÿæˆåˆæ­¥åˆ†æçš„SQLæŸ¥è¯¢...",
            "stage_info": "é˜¶æ®µ 1/4ï¼šç”Ÿæˆåˆæ­¥æŸ¥è¯¢" if lang == 'zh' else "Stage 1/4: Generating Initial Query"
        })
        system_prompt = FULL_SYSTEM_PROMPT_EN if lang == 'en' else FULL_SYSTEM_PROMPT
        llm_response1 = get_llm_response_structured(
            [{"role": "user", "content": job["original_query"]}], system_prompt, lang=lang
        )
        print("[Orchestrator] <== STAGE 1: å®Œæˆ")

        if not llm_response1 or not llm_response1.get("sql_query"):
            job.update({"job_status": "FAILED", "status_message": "æœªèƒ½ç”Ÿæˆåˆæ­¥SQLæŸ¥è¯¢ã€‚"})
            job.update({"job_status": "FAILED", "status_message": "æœªèƒ½ç”Ÿæˆåˆæ­¥SQLæŸ¥è¯¢ã€‚"})
            if llm_response1:
                explanation = llm_response1.get("explanation")
            recommended_analyses = llm_response1.get("recommended_analyses")
            if explanation:
                print(f"LLM Explanation on failure: {explanation}")
            if recommended_analyses:
                print(f"LLM Recommended Analyses on failure: {recommended_analyses}")
        else:
            baseline_df, error_msg = execute_sql(llm_response1["sql_query"], df_data)
            if baseline_df is None:
                job.update({"job_status": "FAILED", "status_message": "æ‰§è¡Œåˆæ­¥SQLæŸ¥è¯¢å¤±è´¥ã€‚"})
            else:
                job["stages"]["stage1_baseline"] = {"data": baseline_df, "sql": llm_response1["sql_query"]}
                job["job_status"] = "STAGE1_COMPLETE"  # æ›´æ–°åˆ°ä¸‹ä¸€çŠ¶æ€
        st.rerun()

    # é˜¶æ®µäºŒï¼šä» "STAGE1_COMPLETE" çŠ¶æ€å¼€å§‹ï¼Œè§„åˆ’åˆ†ææ­¥éª¤
    elif status == "STAGE1_COMPLETE":
        print("\n[Orchestrator] ==> STAGE 2: åŸºäºåˆæ­¥æ•°æ®è§„åˆ’æ·±åº¦åˆ†æ...")
        job.update({
            "status_message": "å·²å‘ç°å…³é”®ä¿¡æ¯ï¼Œæ­£åœ¨è§„åˆ’æ·±åº¦æ¢æŸ¥æ–¹æ¡ˆ...",
            "stage_info": "é˜¶æ®µ 2/4ï¼šè§„åˆ’æ·±åº¦åˆ†æ" if lang == 'zh' else "Stage 2/4: Planning Deep Dive"
        })
        baseline_df = job["stages"]["stage1_baseline"]["data"]

        system_prompt = FULL_SYSTEM_PROMPT_EN if lang == 'en' else FULL_SYSTEM_PROMPT
        analysis_plan_json = get_analysis_plan(job["original_query"], baseline_df.head(20), system_prompt, lang=lang)
        print("[Orchestrator] <== STAGE 2: å®Œæˆ")

        if not analysis_plan_json or "plan" not in analysis_plan_json or not analysis_plan_json["plan"]:
            job.update({"job_status": "FAILED", "status_message": "æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„åˆ†æè®¡åˆ’ã€‚"})
        else:
            job["stages"]["stage2_plan"] = analysis_plan_json["plan"]
            job["stages"]["stage3_evidence"] = {}  # åˆå§‹åŒ–ç”¨äºå­˜å‚¨è¯æ®
            job["job_status"] = "STAGE2_COMPLETE"  # æ›´æ–°åˆ°ä¸‹ä¸€çŠ¶æ€
        st.rerun()

    # é˜¶æ®µä¸‰ï¼šä» "STAGE2_COMPLETE" çŠ¶æ€å¼€å§‹ï¼Œæ‰§è¡Œè®¡åˆ’
    elif status == "STAGE2_COMPLETE":
        print("\n[Orchestrator] ==> STAGE 3: æ‰§è¡Œåˆ†æè®¡åˆ’å¹¶æ”¶é›†æ•°æ®...")
        job.update(
            {"stage_info": "é˜¶æ®µ 3/4ï¼šæ‰§è¡Œå¹¶æ”¶é›†æ•°æ®" if lang == 'zh' else "Stage 3/4: Executing & Gathering Data"})
        plan = job["stages"]["stage2_plan"]

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½å·²æ‰§è¡Œ
        current_step_index = len(job["stages"]["stage3_evidence"])
        if current_step_index < len(plan):
            step = plan[current_step_index]
            print(f"[Orchestrator]     - STAGE 3.{current_step_index + 1}: {step['purpose']}")
            job["status_message"] = f"æ­£åœ¨æ‰§è¡Œç¬¬ {current_step_index + 1}/{len(plan)} æ­¥: {step['purpose']}"
            evidence_df, error_msg = execute_sql(step['sql'], df_data)
            job["stages"]["stage3_evidence"][f"evidence_{current_step_index + 1}"] = {
                "purpose": step["purpose"], "dataframe": evidence_df,
                "data_markdown": evidence_df.to_markdown(index=False) if evidence_df is not None else "æŸ¥è¯¢å¤±è´¥æˆ–æ— æ•°æ®ã€‚"
            }
            # ä¿æŒçŠ¶æ€ä¸å˜ï¼Œä»¥ä¾¿å¾ªç¯æ‰§è¡Œä¸‹ä¸€æ­¥
        else:
            print("[Orchestrator] <== STAGE 3: æ‰€æœ‰æ­¥éª¤å®Œæˆ")
            job["job_status"] = "STAGE3_COMPLETE"  # æ‰€æœ‰æ­¥éª¤å®Œæˆåï¼Œæ›´æ–°åˆ°ä¸‹ä¸€çŠ¶æ€
        st.rerun()

    # é˜¶æ®µå››ï¼šä» "STAGE3_COMPLETE" çŠ¶æ€å¼€å§‹ï¼Œç”ŸæˆæŠ¥å‘Š
    elif status == "STAGE3_COMPLETE":
        print("\n[Orchestrator] ==> STAGE 4: ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        job.update({
            "status_message": "æ‰€æœ‰æ•°æ®å·²æ”¶é›†ï¼Œæ­£åœ¨æ’°å†™æœ€ç»ˆåˆ†ææŠ¥å‘Š...",
            "stage_info": "é˜¶æ®µ 4/4ï¼šç»¼åˆåˆ†ææŠ¥å‘Š" if lang == 'zh' else "Stage 4/4: Synthesizing Report"
        })
        # evidence_for_llm = {k: {"purpose": v["purpose"], "data": v["data_markdown"]} for k, v in
        #                     job["stages"]["stage3_evidence"].items()}
        evidence_for_llm = job["stages"]["stage3_evidence"]
        final_report_json = get_synthesized_report(job["original_query"], evidence_for_llm, lang=lang)
        print("[Orchestrator] <== STAGE 4: å®Œæˆ")
        print("\n================== [æ™ºèƒ½æŠ¥å‘Šæµç¨‹ç»“æŸ] ==================")

        if not final_report_json:
            job.update({"job_status": "FAILED", "status_message": "æœªèƒ½ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚"})
        else:
            job["stages"]["stage4_report"] = final_report_json
            job["job_status"] = "DONE"  # ä»»åŠ¡æœ€ç»ˆå®Œæˆ
        st.rerun()