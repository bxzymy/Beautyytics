注意：本报告由AI生成！

### Beautyytics / 妆策灵析

**1. 执行摘要**

本报告对 “Beautyytics” (妆策灵析) 应用进行技术分析，这是一个使用 Streamlit 构建的双语数据分析平台。该系统旨在通过将自然语言查询翻译为可执行的SQL、执行数据分析并通过文本和可视化图表呈现洞察，以弥合业务用户与复杂数据集之间的鸿沟。该实现以其模块化架构、复杂的大语言模型（LLM）编排以及两种截然不同的操作模式而著称：标准的交互式问答模式和先进的多步骤“智能报告”生成工作流。其代码库展示了构建人工智能驱动的数据应用的稳健且结构良好的方法。

**2. 核心架构**

该应用在 Streamlit 框架内被构建为一个单页应用（SPA）。“主页”和“分析”视图之间的页面导航是通过 Streamlit 的 `session_state` 控制的，而非其原生的多页应用功能。这一设计选择提供了集中的状态管理，这对于在整个用户旅程中维护上下文、对话历史和语言偏好至关重要。

系统的组件被逻辑上分离到不同的模块中：

- **`app.py`**：主入口文件，根据会话状态将用户路由到主页或分析页面。
- **`home_page.py`**：渲染静态着陆页，提供介绍和语言选择功能。
- **`analysis_page.py`**：主要的交互模块。它管理分析界面的用户界面（UI），处理用户输入，并编排对后端逻辑的调用。
- **`sql.py`**：核心逻辑控制器。它包含管理用户输入、LLM 和数据库之间交互的函数。
- **`llm_response.py`**：一个专用模块，负责与外部 LLM API（阿里云的 DashScope）的所有通信。
- **`prompt.py`**、**`prompt_model.py`**：所有提示工程模板的中央存储库，确保一致性和可维护性。
- **`chart.py`**：一个用于生成 Plotly 图表的工具模块，将可视化逻辑与主应用流程分离。
- **`load_data.py`**（被引用）：一个负责将初始数据集加载到 Pandas DataFrame 的模块。

**3. 关键组件与功能**

**3.1. 数据处理与执行**

- **数据库引擎**：系统使用在内存模式下运行的 DuckDB。在运行时，应用程序从数据源（例如 CSV 文件）加载数据到 Pandas DataFrame，然后将其注册为 DuckDB 实例中名为 `df_data` 的表。
- **执行流程**：所有由 LLM 生成的 SQL 查询都在此内存中的 DuckDB 数据库上执行。这种方法对于在大小适中、静态的数据集上执行复杂的即席分析查询非常高效，且没有外部数据库服务器的开销。

**3.2. LLM 交互与提示工程**

- **LLM 服务**：该应用配置为使用阿里云的 DashScope 服务，并特别指定了 `qwen3-30b-a3b` 模型。所有的 API 通信都集中在 `llm_response.py` 模块中。
- **结构化提示**：系统的可靠性取决于其复杂的提示工程。
  - **`DATABASE_SCHEMA_DESCRIPTION`**：一个详细的提示，为 LLM 提供了 `df_data` 表的完整模式，包括列名、数据类型和关于数据的重要上下文（例如，在 `order_type` 中 ‘1’ 和 ‘0’ 代表什么）。这对于生成准确的 SQL 至关重要。
  - **严格的 JSON 输出**：系统提示明确指示 LLM 返回一个 JSON 对象，并定义了所需的确切键（`sql_query`、`chart_type`、`explanation`等）。这将 LLM 转换为一个可预测的 API，是构建智能体系统的最佳实践。
  - **分析框架**：`prompt_model.py` 中的 `BeautyAnalyticsPrompts` 类是一个突出特点。它们为各种分析方法（如描述性、诊断性、SWOT分析）包含了详细的、特定领域的模板。通过允许用户选择一个框架，该应用为 LLM 提供了强大的高级别上下文，引导其执行比简单问题所能达到的更深入、更相关的分析。

**4. 操作工作流**

该应用程序具有两种截然不同的数据分析工作流程，可由用户选择。

**4.1. 标准模式：交互式问答**

此模式遵循一个为快速、迭代式分析而设计的双重 LLM 调用链。

1. **文本到SQL（调用1）**：用户的自然语言查询和对话历史通过 `get_llm_response_structured` 函数发送给 LLM。其目标是生成一个结构化的 JSON 对象，其中包含可执行的 SQL 查询和初步的可视化建议。
2. **SQL 执行**：提取出的 SQL 查询将在内存中的 DuckDB 数据库上执行。
3. **数据到洞察（调用2）**：查询返回的 DataFrame 会被转换为 Markdown 格式，并通过 `get_final_analysis_and_chart_details` 函数发送给 LLM。LLM 的任务是分析数据本身，提供洞察的文本摘要，并返回一组用于生成图表的确定性参数（例如，最终的图表类型、坐标轴、标题和详细解释）。
4. **渲染**：最终的分析文本和图表将展示给用户。

**4.2. 智能报告模式：自主智能体工作流**

这个高级模式由 `process_user_query_orchestrator` 函数编排，其功能类似于一个状态机，引导 LLM 完成一个多步骤的分析过程，以生成一份全面的报告。

- **阶段1：初始数据检索**：基于用户的高阶主题（例如，“分析销售表现”），LLM 首先生成一个宽泛的 SQL 查询以获取基线数据摘要。
- **阶段2：分析规划**：基线数据摘要会使用一个专门的 `PLANNER_PROMPT` 反馈给 LLM。LLM 扮演“数据分析总监”的角色，设计一个多步骤的分析计划，并输出一系列假设以及调查这些假设所需的 SQL 查询。
- **阶段3：证据收集**：系统迭代执行生成的计划，按顺序执行每个 SQL 查询。每个查询的结果都作为一条“证据”（一个 DataFrame 及其目的）被存储起来。
- **阶段4：报告合成**：所有收集到的证据（多个带有上下文的 DataFrame）被汇总，并使用一个最终的 `SYNTHESIZER_PROMPT` 发送给 LLM。LLM 的角色转变为“数据故事讲述者”，将零散的发现编织成一个单一、连贯的叙述性报告，报告中包含标题、摘要、章节（每个章节都包含文本和相应的图表）以及战略建议。
- **阶段5：最终渲染**：完整的结构化报告将在用户界面中渲染出来。

**5. 结论**

“Beautyytics” 应用是一个精心设计的平台，它有效地展示了 LLM 在现代数据分析中的强大能力。其优势在于其模块化设计、稳健且集中的提示管理，以及为实现自主报告生成而设计的复杂的、类似智能体的工作流。通过将用户友好的 Streamlit 界面与一个能够智能编排 LLM 调用和数据执行的强大后端相结合，该系统为实现数据驱动的决策提供了一个极具吸引力的解决方案。
